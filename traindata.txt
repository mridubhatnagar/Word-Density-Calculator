big data is a term for data sets that are so large or complex that traditional data processing applications are inadequate to deal with them  Challenges include analysis capture data curation search sharing storage transfer visualization querying updating and information privacy The term big data often refers simply to the use of predictive analytics user behavior analytics or certain other advanced data analytics methods that extract value from data and seldom to a particular size of data set Accuracy in big data may lead to more confident decision making and better decisions can result in greater operational efficiency cost reduction and reduced risk Analysis of data sets can find new correlations to spot business trends prevent diseases combat crime and so on  Scientists business executives  practitioners of medicine  advertising and governments alike regularly meet difficulties with large data sets in areas including Internet search  finance  urban informatics  and business informatics Scientists encounter limitations in e Science work including meteorology genomics  connectomics  complex physics simulations  biology and environmental research data sets grow rapidly  in part because they are increasingly gathered by cheap and numerous information sensing mobile devices  aerial  remote sensing   software logs  cameras  microphones  radio frequency identification  RFID  readers and wireless sensor networks  The world's technological per capita capacity to store information has roughly doubled every 40 months since the 1980s  as of 2012  every day 2 5 exabytes of data is generated One question for large enterprises is determining who should own big data initiatives that affect the entire organization Relational database management systems and desktop statistics  and visualization packages often have difficulty handling big data  The work may require   massively parallel software running on tens  hundreds  or even thousands of servers   What counts as   big data   varies depending on the capabilities of the users and their tools  and expanding capabilities make big data a moving target    For some organizations  facing hundreds of gigabytes of data for the first time may trigger a need to reconsider data management options For others  it may take tens or hundreds of terabytes before data size becomes a significant consideration   big data usually includes data sets with sizes beyond the ability of commonly used software tools to capture  curate  manage  and process data within a tolerable elapsed time  big data   size   is a constantly moving target  as of 2012 ranging from a few dozen terabytes to many petabytes of data  big data requires a set of techniques and technologies with new forms of integration to reveal insights from datasets that are diverse  complex  and of a massive scale In a 2001 research report and related lectures  META Group  now Gartner  analyst Doug Laney defined data growth challenges and opportunities as being three dimensional  i e  increasing volume  amount of data   velocity  speed of data in and out   and variety  range of data types and sources   Gartner  and now much of the industry  continue to use this   3Vs   model for describing big data In 2012  Gartner updated its definition as follows     big data is high volume  high velocity  and/or high variety information assets that require new forms of processing to enable enhanced decision making  insight discovery and process optimization    Gartner's definition of the 3Vs is still widely used  and in agreement with a consensual definition that states that   big data represents the Information assets characterized by such a High Volume  Velocity and Variety to require specific Technology and Analytical Methods for its transformation into Value   Additionally  a new V   Veracity   is added by some organizations to describe it revisionism challenged by some industry authorities  The 3Vs have been expanded to other complementary characteristics of big data  Volume   big data doesn't sample  it just observes and tracks what happens Velocity   big data is often available in real time Variety   big data draws from text  images  audio  video  plus it completes missing pieces through data fusion Machine Learning   big data often doesn't ask why and simply detects patterns Digital footprint   big data is often a cost free byproduct of digital interaction The growing maturity of the concept more starkly delineates the difference between big data and Business Intelligence  Business Intelligence uses descriptive statistics with data with high information density to measure things  detect trends  etc  big data uses inductive statistics and concepts from nonlinear system identification to infer laws  regressions  nonlinear relationships  and causal effects  from large sets of data with low information density to reveal relationships and dependencies  or to perform predictions of outcomes and behaviors 